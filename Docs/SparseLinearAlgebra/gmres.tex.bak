\subsection{\label{sec:GMRES}\index{GMRES}GMRES}

This section we follow Refs.~\cite{templates} and \cite{sparselinearbook1}.

Assume a set of basis has been found. For example, if the subspace is found by using modified Gram-Schmidt as
\begin{algorithm}[H]
\begin{algorithmic}
\State ${\bf v}^{(0)}\:={\bf x}_0/\|{\bf x}_0\|$
\For{$i=0$ to $k-1$}
    \State ${\bf w}\:=A{\bf v}^{(i)}$
    \For{$j=0$ to $i$}
        \State $c={{\bf v}^{(j)}}^*\cdot {\bf w}$
        \State ${\bf w}-=c{\bf v}^{(j)}$
        \State $h[j,i]=c$
    \EndFor
    \State $h[i+1,i]=\|{\bf w}\|$
    \State ${\bf v}^{(i+1)}={\bf w}/\|{\bf w}\|$
\EndFor
\end{algorithmic}
\caption{\label{alg.ArnoldiModifiedGS}Arnoldi with modified Gram-Schmidt}
\end{algorithm}

Note that $\left({\bf w}-\left({\bf v}_i^*\cdot {\bf w}\right){\bf v}_i\right)^* \cdot {\bf v}_i=0$, and ${\bf x}_0$ is a trail solution, which can be set to be ${\bf b}$ at first. Now we obtain $k+1$ unitary orthogonal vectors, such that
\begin{equation}
\begin{split}
&{\bf v}_i^*\cdot {\bf v}_j=\delta _{ij},\;\;A{\bf v}_{i-1}=\sum _{j=0}^i h[j,i-1]{\bf v}_j,\\
\end{split}
\end{equation}

That is
\begin{equation}
\begin{split}
&\left(\begin{array}{c}Av_0 \\ Av_1 \\ Av_2 \\ \ldots \\ Av_{k-1}\end{array}\right)=\left(v_0,v_1,\ldots,v_{k-1},v_k\right)\left(\begin{array}{ccccc}
$h[0,0]$ & $h[0,1]$ & $\ldots$ & $h[0,k-2]$ & $h[0,k-1]$ \\
$h[1,0]$ & $h[1,1]$ & $\ldots$ & $h[1,k-2]$ & $h[1,k-1]$ \\
$0$ & $h[2,1]$ & $\ldots$ & $h[2,k-2]$ & $h[2,k-1]$ \\
$0$ & $0$ & $\ldots$ & $\ldots$ & $\ldots$ \\
$\ldots$ & $\ldots$ & $\ldots$ & $h[k-1,k-2]$ & $h[k-1,k-1]$ \\
$0$ & $0$ & $\ldots$ & $0$ & $h[k,k-1]$ \\
\end{array}\right)\\
\end{split}
\end{equation}
which can be written as
\begin{equation}
\begin{split}
&(Av)_k=v_{k+1}H
\end{split}
\label{eq,gemres.1}
\end{equation}
The solution can be written as
\begin{equation}
\begin{split}
&{\bf x}={\bf x}_0 + \sum _{i=0}^{k-1} y_i {\bf v}_i={\bf x}_0+{\bf y}={\bf x}_0+v_ky,\\
\end{split}
\end{equation}
Using ${\bf r}_0={\bf b}-A{\bf x}_0$, to minimize $\|{\bf b}-A{\bf x}\|$ is to minimize $\|{\bf r}_0-A{\bf y}\|$. We always choose ${\bf v}_0={\bf r}_0/\|{\bf r}_0\|$, denote $\beta = \|{\bf r}_0\|$, it is to minimize
\begin{equation}
\begin{split}
&{\rm argmin}\|\beta {\bf e}_0 - Hy\|.\\
\end{split}
\end{equation}
Or, to solve an equation in $k$ dimension
\begin{equation}
\begin{split}
&\beta {\bf e}_0 - Hy=0,\;\;y=H^{-1}\beta {\bf e}_0=H^{-1} g\\
\end{split}
\end{equation}

Now, we need to solve $H^{-1}$, we can do this by applying rotation matrix, defining
\begin{equation}
\begin{split}
&J_0=
{\left.\left(\begin{array}{cc}
 R & 0 \\
0 & \mathbb{I}_{k-2} \\
\end{array}\right)\right. }_{D=k}
={\left.\left(\begin{array}{ccccc}
\textcolor[rgb]{1,0,0}{c_0^*} & \textcolor[rgb]{1,0,0}{s_0^*} & 0 & \ldots & 0 \\
-s_0 & c_0 & 0 & \ldots & 0 \\
0 & 0 & 1 & \ldots & 0 \\
0 & 0 & \ldots & \ldots & 0 \\
0 & 0 & 0 & 0 & 1 \\
\end{array}\right)\right. }_{D=k}
\end{split}
\end{equation}
\textbf{Note that $c_0^*$ and $s_0^*$ is necessary to keep unitary. ($s_0^*$ seems not necessary? we only need to keep the length of $g$ unchanged)} So that
\begin{equation}
\begin{split}
&0=g-Hy\to 0=J_0g-J_0Hy\\
\end{split}
\end{equation}

with (Note that the first 2 lines are changed entirely)
\begin{equation}
\begin{split}
&H'=\left(\begin{array}{ccccc}
\textcolor[rgb]{0,0,1}{h}'_{0,0} & \textcolor[rgb]{0,0,1}{h}'_{0,1} & \textcolor[rgb]{0,0,1}{h}'_{0,2} & \ldots & \textcolor[rgb]{0,0,1}{h}'_{0,k-1} \\
0 & \textcolor[rgb]{0,0,1}{h}'_{1,1} &\textcolor[rgb]{0,0,1}{h}'_{1,2} & \ldots & \textcolor[rgb]{0,0,1}{h}'_{1,k-1} \\
0 & h_{2,1} & h_{2,2} & \ldots & h_{2,k-1} \\
0 & 0 & \ldots & \ldots & 0 \\
0 & 0 & 0 & 0 & h_{k,k-1} \\
\end{array}\right)\\
&g'=\left(c_0^*\beta,-s_0\beta,0,\ldots\right)\\
&c_0=\frac{h_{00}}{\sqrt{h_{00}^2+h_{10}^2}},\;\;s_0=\frac{h_{10}}{\sqrt{h_{00}^2+h_{10}^2}}
\end{split}
\end{equation}
where $\mathbb{I}_l$ is dimension $l$ identity matrix. Similarly, after this, one can rotation matrices
\begin{equation}
\begin{split}
&J_1=
{\left.\left(\begin{array}{ccc}
 \mathbb{I}_1 & 0 & 0 \\
0 & R & 0 \\
0 & 0 & \mathbb{I}_{k-3} \\
\end{array}\right)\right. }_{D=k},
J_2=
{\left.\left(\begin{array}{ccc}
 \mathbb{I}_2 & 0 & 0 \\
0 & R & 0 \\
0 & 0 & \mathbb{I}_{k-4} \\
\end{array}\right)\right. }_{D=k},\ldots
\end{split}
\end{equation}
To make $H$ triangular.

The algorithm is
\begin{algorithm}[H]
\begin{algorithmic}
\State $g[0]=\beta$
\For{$i=0$ to $k-1$}
    \State $d=1 / \sqrt{|h[i,i]|^2+|h[i+1,i]|^2}$
    \State $cs=h[i,i] \times d,sn=h[i+1,i] \times d$
    \For{$j=i$ to $k-1$}
        \State $h_{ij}=h[i,j]$
        \State $h[i,j]=cs^* \times h_{ij}+ sn^* \times h[i+1,j]$
        \State $h[i+1,j]=cs \times h[i+1,j] - sn \times h_{ij}$
    \EndFor
    \State $minus_g=-g[i]$
    \State $g[i] = cs^* \times g[i]$
    \State $g[i+1] = sn \times minus_g$
\EndFor
\end{algorithmic}
\caption{\label{alg.GEMRES.RotateH}Rotate H}
\end{algorithm}

After the rotation, $g[k]$ is the residue. If it is small enough, the last step is to solve $y=H^{-1}g$, where $H$ is a upper triangular matrix. It can be iterated as
\begin{equation}
\begin{split}
&y[k-1]=\frac{g[k-1]}{h[k-1,k-1]}.\;y[k-2]=\frac{1}{h[k-2,k-2]}\left(g[k-2]-h[k-2,k-1]y[k-1]\right),\ldots\\
\end{split}
\end{equation}
The algorithm is
\begin{algorithm}[H]
\begin{algorithmic}
\For{$i=k-1$ to $0$}
    \For{$j=i+1$ to $k-1$}
        \State $g[j]-=h[i,j]\times y[j]$
    \EndFor
    \State $y[i] = g[i] / h[i,i]$
\EndFor

\Return ${\bf x}_0+\sum _{i=0}^{k-1}y[i]{\bf v}^{(i)}$
\end{algorithmic}
\caption{\label{alg.GEMRES.SolveY}Solve Y}
\end{algorithm}

Note that, the first step, the modified Gram-Schmidt step will produce more and more unitary normalized vectors, so the GMRES usually has a restart step. Let $r$ denote the restart times, for example, the full algorithm with $k$ is (GMRES(m) means GMRES with modified Gram-Schmidt, there is also GMRES with Household, etc)
\begin{algorithm}[H]
\begin{algorithmic}
\State ${\bf x}_0={\bf b}$
\Comment {Use ${\bf b}$ as trail and start}
\For{$i=1$ to $r$}
    \State ${\bf r}_0={\bf b}-A{\bf x}_0$
    \State $\beta = \|{\bf r}_0\|$
    \State ${\bf v}^{(0)}\:={\bf r}_0/\beta$
    \For{$i=0$ to $k-1$}
        \State ${\bf w}\:=A{\bf v}^{(i)}$
        \For{$j=0$ to $i$}
            \State $c={{\bf v}^{(j)}}^*\cdot {\bf w}$
            \State ${\bf w}-=c{\bf v}^{(j)}$
            \State $h[j,i]=c$
        \EndFor
        \State $h[i+1,i]=\|{\bf w}\|$
        \State ${\bf v}^{(i+1)}={\bf w}/\|{\bf w}\|$
    \EndFor
    \State $RotateH(k)$
    \State ${\bf x}=SolveY(k)$
    \If {$|g[k]|< \epsilon$}

        \Return ${\bf x}$
        \Comment {Succeed, with the solution}
    \EndIf
    \State ${\bf x}_0={\bf x}$
    \Comment {Use the last solution as trail and restart}
\EndFor

\Return $x$
\Comment {Failed, with the last best solution}
\end{algorithmic}
\caption{GMRES(m)}
\end{algorithm}
where $RotateH(k)$ and ${\bf x}=SolveY(k)$ is described in Algorithms.~\ref{alg.GEMRES.RotateH} and \ref{alg.GEMRES.SolveY}.


